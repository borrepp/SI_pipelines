{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spikeinterface.core as si\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.curation as scur\n",
    "from spikeinterface.comparison import compare_two_sorters\n",
    "\n",
    "\n",
    "n_cpus = os.cpu_count()\n",
    "n_jobs = n_cpus - 2\n",
    "\n",
    "job_kwargs = dict(chunk_duration=\"1s\", n_jobs=n_jobs, progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SORTING ANALYZER\n",
    "# Set the path of where the sorting analyzer was created. It should exists within the \"parentSortingFolder\". Binary recording will exists in the same parent folder\n",
    "sorter_analyzer_folder = \"M:\\\\AlbusSorting_Results\\\\exp2024-04-03_sorting\\\\exp2024-04-03-sess-0_3-raw-D1-385\\\\exp2024-04-03-sess-0_3-raw-D1-385_MS5s2ch0th4\"\n",
    "sorting_analyzer = si.load_sorting_analyzer(sorter_analyzer_folder, load_extensions=True)\n",
    "\n",
    "\n",
    "# PRINT SOME GENERAL UNITS INFORMATION\n",
    "print('number of units : ', sorting_analyzer.get_num_units())\n",
    "print('total number of spikes : ',sorting_analyzer.sorting.count_total_num_spikes())\n",
    "\n",
    "print('unit IDs : ', sorting_analyzer.unit_ids)\n",
    "print('spikes per unit :')\n",
    "for u, n in sorting_analyzer.sorting.count_num_spikes_per_unit().items():\n",
    "    print('\\tunit \"{}\" : {}\\n'.format(u, n))\n",
    "\n",
    "print('Current Sorting Analyzer contains the following extensions:')\n",
    "for e in sorting_analyzer.get_saved_extension_names():\n",
    "    print('\\t{}'.format(e))\n",
    "\n",
    "\n",
    "print('Sorting properties : ')\n",
    "for p, v in sorting_analyzer.sorting._properties.items():\n",
    "    print('\\t{} : {}'.format(p, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality metrics as dataframe\n",
    "quality_metrics_pd = sorting_analyzer.get_extension('quality_metrics').get_data()\n",
    "quality_metrics_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT A GENERAL OVERVIEW OF THE UNITS\n",
    "%matplotlib ipympl\n",
    "sw.plot_unit_locations(sorting_analyzer, backend=\"ipywidgets\")\n",
    "sw.plot_all_amplitudes_distributions(sorting_analyzer, figsize=(10,4))\n",
    "sw.plot_amplitudes(sorting_analyzer, plot_histograms=True, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the sorter with itself to point to similar units\n",
    "comparison = compare_two_sorters(sorting_analyzer.sorting, sorting_analyzer.sorting, delta_time=1)\n",
    "\n",
    "%matplotlib ipympl\n",
    "sw.plot_agreement_matrix(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore individual neurons:\n",
    "%matplotlib ipympl\n",
    "unit_id = 1\n",
    "sw.plot_unit_summary(sorting_analyzer, unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a pair (or more) neurons\n",
    "unit_id_1 = 1\n",
    "unit_id_2 = 1 # Against itself\n",
    "\n",
    "# Add as many as you want:\n",
    "units2explore = [unit_id_1, unit_id_2] \n",
    "\n",
    "%matplotlib ipympl\n",
    "for u in units2explore:\n",
    "    sw.plot_unit_summary(sorting_analyzer, unit_id=u)\n",
    "\n",
    "sw.plot_crosscorrelograms(sorting_analyzer,  unit_ids=units2explore)\n",
    "sw.plot_unit_templates(sorting_analyzer, unit_ids=units2explore)\n",
    "sw.plot_template_metrics(sorting_analyzer,  unit_ids=units2explore)\n",
    "sw.plot_template_similarity(sorting_analyzer,  unit_ids=units2explore, display_diagonal_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how to merge or split using spikeinterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no need to merge units, apply Labels manually : value must be a list of labels for all the sorted units \n",
    "sorting_analyzer.sorting.set_property(key ='quality', value=['mua'])\n",
    "print(sorting_analyzer.sorting._properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply curation dict to a Sorting or a SortingAnalyzer\n",
    "# Use this method only if there is units to merge\n",
    "#\n",
    "# Steps are done in this order:\n",
    "#  1)      Apply removal using curation_dict[“removed_units”]\n",
    "#  2)      Apply merges using curation_dict[“merge_unit_groups”]\n",
    "#  3)      Set labels using curation_dict[“manual_labels”]\n",
    "\n",
    "\n",
    "# Sample Dictionary to be applied on the result to have a “clean” result\n",
    "curation_dict = dict(\n",
    "    format_version = \"1\",\n",
    "    # Define LABELS\n",
    "    # For label category with exclusive=True : a column is created and values are the unique label.\n",
    "    # For label category with exclusive=False : one column per possible is created and values are boolean.\n",
    "    label_definitions = dict(\n",
    "        quality = dict(label_options = [\"good\", \"noise\", \"mua\", \"artifact\"], exclusive = True)\n",
    "        # Keep adding custom labels:\n",
    "        # putative_type = dict(label_options = [\"excitatory\", \"inhibitory\", \"pyramidal\", \"mitral\"], exclusive = False)\n",
    "    ),\n",
    "    # \n",
    "    unit_ids = sorting_analyzer.unit_ids,\n",
    "    removed_units = [], # List of units to remove. Example: [31, 42]\n",
    "    merge_unit_groups = [[], []], # List of Lists of units to merge (at least 2 units require). Example: [[3, 6], [10, 14, 20]]\n",
    "    manual_labels = [\n",
    "        dict(unit_id = 1, quality = [\"mua\"]),\n",
    "        # Keep adding neurons' labels. Example:\n",
    "        # dict(unit_id = 2, quality = [\"noise\"], putative_type = [\"excitatory\", \"pyramidal\"])\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Might be some errors while trying to add labels. Comments have been posted to the spikeinterface github \n",
    "scur.apply_curation(sorting_or_analyzer=sorting_analyzer, \n",
    "    curation_dict = curation_dict,\n",
    "    censor_ms=0.25,\n",
    "    new_id_strategy=\"append\",\n",
    "    merging_mode=\"soft\",\n",
    "    sparsity_overlap=0.75,\n",
    "    verbose=False,\n",
    "    **job_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save curated sorter analyzer\n",
    "# Add the suffix \n",
    "sorting_analyzer.save_as(format=\"binary_folder\", folder=sorter_analyzer_folder+'_curated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
